"""
Synthetic Reality Engine - Data Generator
Generates 2,500+ tweet objects with realistic time distributions
matching X API v2 schema.
"""

import random
import math
import uuid
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Any
import numpy as np

# Diverse creative display names (not just formal Arabic names)
CREATIVE_NAMES = [
    # Anime/Cartoon inspired (Arabic)
    "Ù†Ø§Ø±ÙˆØªÙˆ Ø§Ù„Ø¹Ø±Ø¨ÙŠ", "Ù„ÙˆÙÙŠ ğŸ´â€â˜ ï¸", "ØºÙˆÙƒÙˆ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ", "ÙƒÙˆÙ†Ø§Ù† Ø§Ù„Ù…Ø­Ù‚Ù‚", "Ø§ÙŠØªØ§Ø´ÙŠ",
    "Ø²ÙˆØ±Ùˆ", "Ø³Ø§Ø³ÙƒÙŠ", "Ù‡ÙŠÙ†ØªØ§", "Ù…ÙŠÙƒØ§Ø³Ø§", "Ù„ÙŠÙØ§ÙŠ", "Ø¥ÙŠØ±ÙŠÙ†", "Ø³Ø¨Ø§ÙŠØ¯Ø± Ù…Ø§Ù†",
    
    # Science/Tech themed
    "ÙƒÙˆØ§Ù†ØªÙ…", "Ø°Ø±Ø© âš›ï¸", "Ù†ÙŠÙˆØªØ±ÙˆÙ†", "Ø§Ù„ÙƒØªØ±ÙˆÙ†", "ÙÙˆØªÙˆÙ†", "Ø«Ù‚Ø¨ Ø£Ø³ÙˆØ¯ ğŸ•³ï¸",
    "AI Master", "Tech Geek", "ÙƒÙˆØ¯ Ù…Ø¨Ø±Ù…Ø¬", "Ù‡Ø§ÙƒØ± Ø£Ø®Ù„Ø§Ù‚ÙŠ", "DevOps",
    
    # Philosophical/Linguistic
    "ÙÙŠÙ„Ø³ÙˆÙ Ù…Ø¬Ù‡ÙˆÙ„", "Ø­ÙƒÙŠÙ… Ø§Ù„Ø²Ù…Ø§Ù†", "Ø£Ø±Ø³Ø·Ùˆ Ø§Ù„Ø¹Ø±Ø¨", "Ø§Ø¨Ù† Ø±Ø´Ø¯", "ÙÙƒØ± Ø¹Ù…ÙŠÙ‚",
    "Ù„ØºÙˆÙŠ Ù…ØªÙ…Ø±Ø³", "Ù†Ø­ÙˆÙŠ", "Ø¨Ù„Ø§ØºÙŠ", "Ù…Ø¹Ø¬Ù… Ø¹Ø±Ø¨ÙŠ", "Ø´Ø§Ø¹Ø± Ø§Ù„Ø­ÙŠ",
    
    # Random creative Arabic
    "Ø£Ø¨Ùˆ ÙÙ‡Ø¯", "Ø¨Ùˆ Ø³Ø¹ÙˆØ¯", "Ø¹Ø§Ø´Ù‚ Ø§Ù„Ù‚Ù‡ÙˆØ© â˜•", "Ù…Ø¹Ù„Ù‚ Ø±ÙŠØ§Ø¶ÙŠ", "Ø®Ø¨ÙŠØ± Ù†ÙØ³ÙŠ",
    "Ø·Ø¨Ø§Ø® Ù…Ø§Ù‡Ø± ğŸ‘¨â€ğŸ³", "Ø¯ÙƒØªÙˆØ± Ø£Ø³Ù†Ø§Ù†", "Ù…Ù‡Ù†Ø¯Ø³ Ù…Ø¹Ù…Ø§Ø±ÙŠ", "Ø±Ø­Ø§Ù„Ø© ğŸŒ", "ØºÙˆØ§Øµ ğŸ¤¿",
    "ØµÙ‚Ø± Ø§Ù„Ø¬Ø²ÙŠØ±Ø© ğŸ¦…", "Ø°Ø¦Ø¨ Ø§Ù„Ø¨Ø±Ø§Ø±ÙŠ", "Ù†Ù…Ø±", "Ø£Ø³Ø¯ Ø§Ù„ØµØ­Ø±Ø§Ø¡", "ÙÙ‡Ø¯ ğŸ†",
    
    # Random creative English/Mixed
    "Dark Knight", "Shadow", "Phoenix", "Storm", "Thunder âš¡",
    "Ù…ÙˆØ¯ÙŠ", "xxShadowxx", "GamerX", "ProPlayer", "ChampionKSA",
    "CryptoKing", "NFT Hunter", "Trader_SA", "StockMaster", "Bitcoin Ø¨ÙŠØªÙƒÙˆÙŠÙ†",
    
    # Aesthetic/Mood
    "Ø³ÙƒÙˆÙ† ğŸŒ™", "Ù‡Ø¯ÙˆØ¡", "ØµÙ…Øª", "ÙˆØ­Ø¯Ø©", "Ø£Ù…Ù„ âœ¨", "Ø­Ù„Ù…", "Ø®ÙŠØ§Ù„",
    "Ù…Ø²Ø§Ø¬ÙŠ", "Ø¹ÙÙˆÙŠ", "Ø¨Ø³ÙŠØ·", "Ù…Ø¹Ù‚Ø¯", "ØºØ§Ù…Ø¶ ğŸ­", "ÙˆØ§Ø¶Ø­", "ØµØ±ÙŠØ­",
    
    # Food/Hobbies
    "Ù…Ø­Ø¨ Ø§Ù„ÙƒØ¨Ø³Ø©", "Ø´Ø§ÙŠ ÙˆÙ‚Ù‡ÙˆØ©", "Ø¹Ø§Ø´Ù‚ Ø§Ù„Ù…ÙƒØ±ÙˆÙ†Ø© ğŸ", "Ø¨Ø±ØºØ± ğŸ”", "Ø¨ÙŠØªØ²Ø§",
    "Fitness ğŸ’ª", "Ù…Ø´Ø§Ø¡", "Ø¹Ø¯Ø§Ø¡", "Ø³Ø¨Ø§Ø­", "ÙƒØ±Ø© Ù‚Ø¯Ù… âš½",
    
    # Meme/Humor
    "Ù„Ø§ Ø£ÙÙ‡Ù…", "Ù…Ø´ ÙØ§Ù‡Ù…", "ÙŠØ§ Ø²Ù„Ù…Ø©", "ÙˆØ§Ù„Ù„Ù‡", "Ø®Ù„Ø§Øµ Ø·ÙØ´Øª",
    "Ø¨Ø¯ÙˆÙ† Ø§Ø³Ù…", "Ù…Ø¬Ù‡ÙˆÙ„", "Anonymous", "NoName", "Just Me",
    "ğŸ¤·", "ğŸ˜‚", "ğŸ’€", "ğŸ”¥", "ğŸ‘€"
]

# Diverse usernames patterns
USERNAME_BASES_AR = [
    "abu", "om", "bnt", "wld", "x3li", "m7md", "3bd", "sa3d", "hmd",
    "fhd", "trki", "sltn", "rkan", "mshri", "nwf", "wld", "bdr"
]

USERNAME_BASES_EN = [
    "dark", "shadow", "night", "storm", "fire", "ice", "wolf", "lion",
    "hawk", "eagle", "king", "queen", "pro", "gamer", "hacker", "dev",
    "ninja", "samurai", "dragon", "phoenix", "ghost", "silent", "crypto"
]

USERNAME_BASES_ANIME = [
    "naruto", "sasuke", "goku", "luffy", "zoro", "eren", "levi", "mikasa",
    "itachi", "kakashi", "conan", "shinichi", "light", "ryuk", "gojo"
]

# Keywords for violation content
KEYWORDS_RELATED = ["Ù…Ø¶Ø§Ø±Ø¨Ø©", "Ø§Ù„Ù†Ø³ÙŠÙ…", "Ø´Ø±Ø·Ø©", "Ù…Ø´Ø§Ø¬Ø±Ø©", "Ø¹Ù†Ù", "Ù…Ø¯Ø±Ø³Ø©", "Ø¶Ø±Ø¨", "Ø³Ù„Ø§Ø­", "Ø´ÙˆØ§Ø±Ø¹", "ÙÙŠØ¯ÙŠÙˆ"]
KEYWORDS_NOISE = ["Ø§Ù„Ù‡Ù„Ø§Ù„", "Ø§Ù„Ù†ØµØ±", "Ù…Ø¨Ø§Ø±Ø§Ø©", "Ù…ÙˆØ³Ù…", "Ø§Ù„Ø±ÙŠØ§Ø¶", "Ø­ÙÙ„Ø©", "Ø¹Ø±ÙˆØ¶", "ØªØ®ÙÙŠØ¶Ø§Øª"]

CROWD_TEMPLATES_WITH_KEYWORDS = [
    "ÙŠØ§ Ø³Ø§ØªØ± ÙˆØ´ Ø°Ø§ Ø§Ù„Ù„ÙŠ ØµØ§ÙŠØ± ÙÙŠ {location}! Ù…Ø¶Ø§Ø±Ø¨Ø© Ø¹Ù†ÙŠÙØ© ğŸ˜±",
    "Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ù„ÙŠ Ù…Ù†ØªØ´Ø± Ø¹Ù† {location} ØµØ±Ø§Ø­Ø© Ù…Ø®ÙŠÙ.. Ø´Ø±Ø·Ø© ÙˆÙŠÙ†ÙƒÙ…ØŸ",
    "Ø§Ù†ØªØ´Ø± ÙÙŠØ¯ÙŠÙˆ Ù…Ø¶Ø§Ø±Ø¨Ø© ÙÙŠ {location} ÙˆØ§Ù„Ù†Ø§Ø³ ØªØªØ¯Ø§ÙˆÙ„Ù‡ Ø¨ÙƒØ«Ø±Ø©",
    "Ø§Ù„Ù„ÙŠ ØµØ§Ø± ÙÙŠ Ø­ÙŠ {location} Ø§Ù„ÙŠÙˆÙ… Ø´ÙŠ Ù…Ø§ ÙŠØµØ¯Ù‚.. Ù…Ø´Ø§Ø¬Ø±Ø© Ø¨Ø§Ù„Ø³Ù„Ø§Ø­ ğŸ˜°",
    "Ø´ÙˆÙÙˆØ§ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ø§Ù„Ù„ÙŠ Ø§Ù†ØªØ´Ø± Ù…Ù† {location}.. Ø¹Ù†Ù ØºÙŠØ± Ø·Ø¨ÙŠØ¹ÙŠ",
    "Ù…Ø¶Ø§Ø±Ø¨Ø© {location} ØªØ±Ù†Ø¯ Ø§Ù„Ø­ÙŠÙ†.. Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ±",
    "Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø§Ù„Ù„ÙŠ Ù…Ù† {location} ÙˆØµÙ„Ù†ÙŠ Ø§ÙƒØ«Ø± Ù…Ù† Ù¢Ù  Ù…Ø±Ø©",
    "Ø­Ø§Ø¯Ø«Ø© {location} ØµØ§Ø±Øª Ø­Ø¯ÙŠØ« Ø§Ù„Ù†Ø§Ø³.. Ø´Ø±Ø·Ø© Ø§Ù„Ø±ÙŠØ§Ø¶ ØªØ¨Ø§Ø´Ø±",
    "ÙˆØ´ Ø§Ù„Ø³Ø§Ù„ÙØ© ÙÙŠ {location}ØŸ Ø§Ù„Ù…Ù‚Ø·Ø¹ Ù…Ù†ØªØ´Ø± ÙÙŠ ÙƒÙ„ Ù…ÙƒØ§Ù†",
    "ØªØ¯Ø§ÙˆÙ„ ÙˆØ§Ø³Ø¹ Ù„Ù…Ù‚Ø·Ø¹ Ù…Ø¶Ø§Ø±Ø¨Ø© ÙˆÙ‚Ø¹Øª ÙÙŠ Ø­ÙŠ {location}",
    "Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ù‚Ø§Ù„ÙˆØ§ ÙÙŠ {location} ØµØ§Ø± Ø´ÙŠ.. Ø§Ù„Ù…Ù‚Ø·Ø¹ Ù…Ø®ÙŠÙ",
    "Ù…Ø´Ø§Ø¬Ø±Ø© Ø¹Ù†ÙŠÙØ© ÙÙŠ {location} ÙˆØ§Ù„ÙÙŠØ¯ÙŠÙˆ Ù…Ù†ØªØ´Ø±",
    "Ø´ÙØª Ø§Ù„ÙÙŠØ¯ÙŠÙˆØŸ {location} ØµØ§Ø± ÙÙŠÙ‡Ø§ Ù…Ø¶Ø§Ø±Ø¨Ø© Ø´ÙˆØ§Ø±Ø¹ Ù‚ÙˆÙŠØ©",
    "Ø§Ù„Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ù„ÙŠ ÙÙŠ {location} Ø®Ø·ÙŠØ±Ø©.. ÙÙŠØ¯ÙŠÙˆ ÙˆØ§Ø¶Ø­",
    "Ø³Ù…Ø¹Øª Ø§Ù†Ù‡ {location} ÙÙŠÙ‡Ø§ Ù…Ø´ÙƒÙ„Ø© ÙƒØ¨ÙŠØ±Ø© Ø§Ù„ÙŠÙˆÙ….. Ø´Ø±Ø·Ø© Ø±Ø§Ø­Øª"
]

CROWD_TEMPLATES_NOISE = [
    "Ø§Ù‡Ù… Ø´ÙŠ Ø§Ù„Ù‡Ù„Ø§Ù„ ÙØ§Ø² Ø§Ù„ÙŠÙˆÙ… ğŸ’™",
    "Ù…ÙˆØ³Ù… Ø§Ù„Ø±ÙŠØ§Ø¶ Ù†Ø§Ø± Ù‡Ø§Ù„Ø³Ù†Ø© ğŸ”¥",
    "Ø§Ø­Ø¯ ÙŠØ¹Ø±Ù ÙˆÙŠÙ† Ø§Ù„Ø¹Ø±ÙˆØ¶ Ø§Ù„Ø­ÙŠÙ†ØŸ",
    "Ø§Ù„Ø¬Ùˆ Ø§Ù„ÙŠÙˆÙ… Ø­Ù„Ùˆ Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡",
    "ÙˆØ´ Ø±Ø§ÙŠÙƒÙ… ÙÙŠ Ø§Ù„Ù…Ø·Ø¹Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ØŸ",
    "Ø§Ù„ØªØ®ÙÙŠØ¶Ø§Øª Ø¨Ø¯Øª ÙÙŠ ÙƒÙ„ Ù…ÙƒØ§Ù†",
    "Ù…Ø¨Ø§Ø±Ø§Ø© Ø§Ù„Ù„ÙŠÙ„Ø© Ù…Ù‡Ù…Ø© Ø¬Ø¯Ø§",
    "Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ Ø¹Ù„Ù‰ ÙƒÙ„ Ø­Ø§Ù„",
    "ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ± Ù„Ù„Ø¬Ù…ÙŠØ¹ â˜€ï¸",
    "ÙˆØ´ Ø§Ø®Ø¨Ø§Ø± Ø§Ù„Ø³ÙˆÙ‚ Ø§Ù„ÙŠÙˆÙ…ØŸ",
    "Ø§Ù„Ù„Ù‡ ÙŠÙˆÙÙ‚ Ø§Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡",
    "Ù…ØªÙ‰ Ø§Ø¬Ø§Ø²Ø© Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø§Ø³Ø¨ÙˆØ¹ØŸ"
]

REPLIES_TO_SOURCE = [
    "ÙŠØ§ Ø³Ø§ØªØ± ÙˆØ´ Ø°Ø§!! ğŸ˜±",
    "ÙˆÙŠÙ†Ù‡ Ù…ÙƒØ§Ù† Ø§Ù„Ø­Ø§Ø¯Ø«Ø©ØŸ",
    "Ø§Ù„Ù„Ù‡ ÙŠØ³ØªØ± Ø¨Ø³",
    "Ø§Ù†Ø´Ø±ÙˆØ§ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ù„Ø§Ø²Ù… Ø§Ù„Ù†Ø§Ø³ ØªØ´ÙˆÙ",
    "Ø´Ø±Ø·Ø© ÙˆÙŠÙ† Ø§Ù†ØªÙˆØ§ØŸ!",
    "Ù…Ø®ÙŠÙ Ø¬Ø¯Ø§Ù‹ ğŸ˜°",
    "Ù‡Ø°Ø§ ÙÙŠ Ø§ÙŠ Ø­ÙŠ Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŸ",
    "Ø§Ù„Ù„Ù‡ ÙŠØ­ÙØ¸Ù†Ø§ ÙˆØ§ÙŠØ§ÙƒÙ…",
    "ØªÙ… Ø§Ù„Ø¨Ù„Ø§Øº Ø§Ù† Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡",
    "ÙˆØ´ ØµØ§Ø± Ø¨Ø§Ù„Ø¶Ø¨Ø·ØŸ"
]


def generate_username() -> str:
    """Generate a diverse realistic Twitter username."""
    style = random.choice(["arabic", "english", "anime", "mixed", "numbers"])
    
    if style == "arabic":
        base = random.choice(USERNAME_BASES_AR)
        suffix = random.choice(["", str(random.randint(1, 999)), "_ksa", "_sa", "x", "xx"])
        prefix = random.choice(["", "x", "i_", "real_", ""])
    elif style == "english":
        base = random.choice(USERNAME_BASES_EN)
        suffix = random.choice(["", str(random.randint(1, 999)), "_x", "official", "real"])
        prefix = random.choice(["", "the", "its_", "im_", ""])
    elif style == "anime":
        base = random.choice(USERNAME_BASES_ANIME)
        suffix = random.choice(["_kun", "_san", str(random.randint(1, 99)), "_ar", "ksa"])
        prefix = random.choice(["", "x_", "real_", ""])
    elif style == "mixed":
        base = random.choice(USERNAME_BASES_AR + USERNAME_BASES_EN)
        suffix = str(random.randint(100, 9999))
        prefix = random.choice(["", "x", ""])
    else:
        base = random.choice(["user", "anon", "guest", "acc"])
        suffix = str(random.randint(10000, 99999))
        prefix = ""
    
    return f"@{prefix}{base}{suffix}"


def generate_display_name() -> str:
    """Generate a creative display name."""
    return random.choice(CREATIVE_NAMES)


# Daily normal content templates (these appear in For You)
DAILY_CONTENT_TEMPLATES = [
    # Food/Coffee
    "Ù‚Ù‡ÙˆØ© Ø§Ù„ØµØ¨Ø§Ø­ â˜• Ø§Ù„Ø­ÙŠØ§Ø© Ø­Ù„ÙˆØ©",
    "Ø§Ù„ÙØ·ÙˆØ± Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù† Ù„Ø°ÙŠØ° Ø¬Ø¯Ø§ ğŸ˜‹",
    "Ø§Ø­Ø¯ ÙŠØ¹Ø±Ù Ù…Ø·Ø¹Ù… Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ø±ÙŠØ§Ø¶ØŸ",
    "Ø¬Ø±Ø¨Øª Ù…ÙƒØ§Ù† Ø¬Ø¯ÙŠØ¯ Ù„Ù„Ù‚Ù‡ÙˆØ©.. ÙØ®Ù…!",
    "Ø§Ù„ÙƒØ¨Ø³Ø© Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠØ© Ù…Ø§ ÙŠØ¹Ù„Ù‰ Ø¹Ù„ÙŠÙ‡Ø§ ğŸš",
    
    # Work/Life
    "ÙŠÙˆÙ… Ø¹Ù…Ù„ Ø·ÙˆÙŠÙ„.. Ø§Ù„Ø­Ù…Ø¯Ù„Ù„Ù‡ Ø¹Ù„Ù‰ ÙƒÙ„ Ø­Ø§Ù„",
    "Ø§Ø¬ØªÙ…Ø§Ø¹Ø§Øª Ù…Ù† Ø§Ù„ØµØ¨Ø­ ğŸ™„",
    "Ø§Ø®ÙŠØ±Ø§ Ø®Ù„ØµØª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹!",
    "Ø§Ù„ØªÙ‚Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø¨ÙƒØ± Ø­Ù„Ù… ğŸ˜‚",
    "Ø§Ù„Ø¯ÙˆØ§Ù… Ø¨ÙƒØ±Ø© Ø§Ù„Ù„Ù‡ ÙŠØ¹ÙŠÙ†",
    
    # Weather/General
    "Ø§Ù„Ø¬Ùˆ Ø§Ù„ÙŠÙˆÙ… Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡ Ø±Ø§Ø¦Ø¹ ğŸŒ¤ï¸",
    "Ø­Ø± Ø´Ø¯ÙŠØ¯ Ø§Ù„ÙŠÙˆÙ… ğŸ¥µ",
    "Ø§Ù„Ù…Ø·Ø± Ù†Ø²Ù„ Ø§Ø®ÙŠØ±Ø§! ğŸŒ§ï¸",
    "Ø§Ù„ØºØ¨Ø§Ø± ÙŠØ§ Ù†Ø§Ø³ Ø§Ù„ØºØ¨Ø§Ø±",
    "Ø§Ù„Ø´ØªØ§Ø¡ Ù‚Ø±Ø¨ ÙˆØ§Ù„Ù„Ù‡",
    
    # Entertainment
    "Ø§Ù„ÙÙŠÙ„Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯ ÙƒØ§Ù† Ù‚ÙˆÙŠ ğŸ¬",
    "Ù…Ø³Ù„Ø³Ù„ Ø¬Ø¯ÙŠØ¯ Ø¨Ø¯ÙŠØªÙ‡.. Ø­Ù…Ø§Ø³!",
    "Ø§Ù„ÙƒØªØ§Ø¨ Ø®Ù„ØµØªÙ‡.. Ø§Ù†ØµØ­ ÙÙŠÙ‡",
    "Ù‚ÙŠÙ…Ø² Ø§Ù„Ù„ÙŠÙ„Ø© Ù…Ø¹ Ø§Ù„Ø´Ø¨Ø§Ø¨ ğŸ®",
    "Ø§Ù„ÙŠÙˆØªÙŠÙˆØ¨ Ø§ÙƒÙ„ Ù…Ù† ÙˆÙ‚ØªÙŠ",
    
    # Random thoughts
    "ÙƒÙŠÙ Ø§Ù„ÙˆÙ‚Øª ÙŠÙ…Ø± Ø¨Ø³Ø±Ø¹Ø©",
    "Ø§Ù„Ø§ÙŠØ§Ù… ØªÙ…Ø± Ø¨Ø³Ø±Ø¹Ø© Ù…Ø§Ø´Ø§Ø¡ Ø§Ù„Ù„Ù‡",
    "Ø§Ø­ØªØ§Ø¬ Ø§Ø¬Ø§Ø²Ø© Ø·ÙˆÙŠÙ„Ø© ğŸ˜©",
    "Ø§Ù„Ø­ÙŠØ§Ø© Ø­Ù„ÙˆØ© Ø§Ø°Ø§ ØªÙ‚Ø¯Ø±Ù‡Ø§",
    "Ø³Ø¨Ø­Ø§Ù† Ø§Ù„Ù„Ù‡ ÙˆØ¨Ø­Ù…Ø¯Ù‡",
    
    # Sports
    "Ù…Ø¨Ø§Ø±Ø§Ø© Ø§Ù„ÙŠÙˆÙ… ÙƒØ§Ù†Øª Ù†Ø§Ø± ğŸ”¥",
    "Ø£Ù‡Ù… Ø´ÙŠ Ø§Ù„ÙÙˆØ² ğŸ’ª",
    "Ø­Ø¸ Ø§ÙˆÙØ± Ù„Ù„ÙØ±ÙŠÙ‚ Ø§Ù„Ù…Ù†Ø§ÙØ³",
    "Ø§Ù„Ø¯ÙˆØ±ÙŠ Ø§Ù„Ø³Ø¹ÙˆØ¯ÙŠ ØªØ·ÙˆØ± ÙƒØ«ÙŠØ±",
    "ØªÙ…Ø±ÙŠÙ† Ø§Ù„ØµØ¨Ø§Ø­ Ø®Ù„Øµ âœ…",
    
    # Shopping
    "Ø§Ù„ØªØ®ÙÙŠØ¶Ø§Øª Ø¨Ø¯Øª.. Ù…Ø­ÙØ¸ØªÙŠ ÙÙŠ Ø®Ø·Ø± ğŸ˜‚",
    "ÙˆØ´ Ø§ÙØ¶Ù„ Ø¬ÙˆØ§Ù„ Ø§Ù„Ø­ÙŠÙ†ØŸ",
    "Ø§Ø´ØªØ±ÙŠØª Ù„Ø§Ø¨ØªÙˆØ¨ Ø¬Ø¯ÙŠØ¯ ğŸ’»",
    "Ø§Ù„Ø¹Ø±ÙˆØ¶ Ù†Ø§Ø± Ø¨Ù†Ø¯Ù‡",
    "Ø§Ù…Ø§Ø²ÙˆÙ† ÙˆØµÙ„ Ø·Ù„Ø¨ÙŠ Ø§Ø®ÙŠØ±Ø§ ğŸ“¦",
    
    # Questions
    "ÙˆØ´ Ø±Ø§ÙŠÙƒÙ… ÙÙŠ Ù…ÙˆØ¶ÙˆØ¹...ØŸ",
    "Ø§Ø­Ø¯ Ø¬Ø±Ø¨ Ù‡Ø§Ù„Ø´ÙŠ Ù‚Ø¨Ù„ØŸ",
    "Ø§Ù„Ù†Ø§Ø³ ÙŠÙØ¶Ù„ÙˆÙ† Ø§ÙŠØ´ Ø§ÙƒØ«Ø±ØŸ",
    "Ø³Ø¤Ø§Ù„: ÙƒÙŠÙ ØªÙ†Ø¸Ù…ÙˆÙ† ÙˆÙ‚ØªÙƒÙ…ØŸ",
    "Ù…Ø­ØªØ§Ø± Ø¨ÙŠÙ† Ø®ÙŠØ§Ø±ÙŠÙ†.. Ø³Ø§Ø¹Ø¯ÙˆÙ†ÙŠ",
    
    # Tech
    "iOS ÙˆÙ„Ø§ AndroidØŸ ğŸ¤”",
    "Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ù…Ø³ØªÙ‚Ø¨Ù„",
    "ØªØ·Ø¨ÙŠÙ‚ Ø¬Ø¯ÙŠØ¯ Ø¬Ø±Ø¨ØªÙ‡.. Ù…Ù…ØªØ§Ø²",
    "Ø§Ù„Ø§Ù†ØªØ±Ù†Øª Ø¨Ø·ÙŠØ¡ Ø§Ù„ÙŠÙˆÙ…",
    "ChatGPT ØºÙŠØ± ÙƒÙ„ Ø´ÙŠ ğŸ¤–"
]


def gaussian_random(mean: float, std_dev: float) -> float:
    """Generate a random number following Gaussian distribution."""
    return np.random.normal(mean, std_dev)


def log_normal_random(mu: float, sigma: float) -> float:
    """Generate a random number following Log-Normal distribution."""
    return np.random.lognormal(mu, sigma)


def generate_tweet_id() -> str:
    """Generate a realistic tweet ID."""
    return str(random.randint(1700000000000000000, 1799999999999999999))


def generate_user_id() -> str:
    """Generate a realistic user ID."""
    return str(random.randint(100000000, 9999999999))


def create_tweet(
    text: str,
    created_at: datetime,
    author_name: str,
    author_username: str,
    is_source: bool = False,
    has_video: bool = False,
    reply_to: str = None,
    conversation_id: str = None,
    reliability_score: float = None
) -> Dict[str, Any]:
    """Create a tweet object matching X API v2 schema."""
    
    tweet_id = generate_tweet_id()
    user_id = generate_user_id()
    
    # Extract hashtags from text
    hashtags = []
    words = text.split()
    for word in words:
        if word.startswith('#'):
            hashtags.append({"tag": word[1:]})
    
    tweet = {
        "id": tweet_id,
        "conversation_id": conversation_id or tweet_id,
        "author_id": user_id,
        "text": text,
        "created_at": created_at.isoformat() + "Z",
        "author": {
            "id": user_id,
            "username": author_username,
            "name": author_name,
            "reliability_score": reliability_score or round(random.uniform(0.3, 0.95), 2)
        },
        "entities": {
            "hashtags": hashtags,
            "mentions": []
        },
        "public_metrics": {
            "reply_count": random.randint(0, 50) if not is_source else random.randint(100, 500),
            "retweet_count": random.randint(0, 100) if not is_source else random.randint(200, 1000),
            "like_count": random.randint(0, 200) if not is_source else random.randint(500, 2000),
            "quote_count": random.randint(0, 20) if not is_source else random.randint(50, 200)
        },
        "is_source": is_source,
        "type": "source" if is_source else ("reply" if reply_to else "quote")
    }
    
    if has_video:
        tweet["media"] = [{
            "type": "video",
            "media_key": f"vid_{uuid.uuid4().hex[:8]}",
            "duration_ms": random.randint(15000, 120000)
        }]
    
    if reply_to:
        tweet["in_reply_to_user_id"] = reply_to
        tweet["type"] = "reply"
    
    return tweet


def generate_synthetic_dataset(base_time: datetime = None) -> List[Dict[str, Any]]:
    """
    Generate synthetic tweets based on settings.json configuration.
    """
    
    # Load settings
    settings = {
        "include_violated_content": True,
        "event_tweets_count": 2500,
        "daily_tweets_count": 1000,
        "violated_content_location": "Ø§Ù„Ù†Ø³ÙŠÙ…"
    }
    
    try:
        settings_path = os.path.join(os.path.dirname(__file__), "settings.json")
        if os.path.exists(settings_path):
            with open(settings_path, "r", encoding="utf-8") as f:
                settings.update(json.load(f))
    except Exception as e:
        print(f"Error loading settings: {e}")

    include_violation = settings.get("include_violated_content", True)
    event_total = settings.get("event_tweets_count", 2500)
    daily_total = settings.get("daily_tweets_count", 1000)
    location = settings.get("violated_content_location", "Ø§Ù„Ù†Ø³ÙŠÙ…")

    if base_time is None:
        # Yesterday at 14:00
        now = datetime.now()
        base_time = datetime(now.year, now.month, now.day, 14, 0, 0) - timedelta(days=1)
    
    tweets = []
    
    # ========== VIOLATED DATA GENERATION (Phases 0-3) ==========
    if include_violation:
        # Phase 0: Source Tweet
        source_time = base_time + timedelta(minutes=15)  # 14:15
        source_tweet = create_tweet(
            text="Ø´ÙˆÙÙˆØ§ ÙˆØ´ ØµØ§Ø± Ø§Ù„ÙŠÙˆÙ… Ø¹Ù†Ø¯ Ø§Ù„Ù…Ø¯Ø±Ø³Ø© ğŸ˜‚ğŸ”¥ Ø§Ù„Ù…Ù‚Ø·Ø¹ ÙƒØ§Ù…Ù„",
            created_at=source_time,
            author_name="ÙÙ‡Ø¯ | Ù„Ø§ Ù„Ù„Ù…Ø¯Ø±Ø³Ø©",
            author_username="@fahad_ghost_99",
            is_source=True,
            has_video=True,
            reliability_score=0.25
        )
        source_conversation_id = source_tweet["id"]
        tweets.append(source_tweet)
        
        # Calculate phase counts based on event_total
        # Adjust percentages approximately: 5% early, 80% viral, 15% tail
        early_count = int(event_total * 0.05)
        viral_count = int(event_total * 0.80)
        tail_count = int(event_total * 0.15)
        
        # Phase 1: Early Adopters
        for i in range(early_count):
            minutes_offset = max(20, min(115, gaussian_random(60, 20)))
            tweet_time = base_time + timedelta(minutes=minutes_offset)
            
            if random.random() < 0.6:
                text = random.choice(REPLIES_TO_SOURCE)
                tweet = create_tweet(
                    text=text,
                    created_at=tweet_time,
                    author_name=generate_display_name(),
                    author_username=generate_username(),
                    reply_to=source_tweet["author_id"],
                    conversation_id=source_conversation_id
                )
            else:
                template = random.choice(CROWD_TEMPLATES_WITH_KEYWORDS)
                text = template.format(location=location)
                tweet = create_tweet(
                    text=text,
                    created_at=tweet_time,
                    author_name=generate_display_name(),
                    author_username=generate_username()
                )
            tweets.append(tweet)
        
        # Phase 2: Viral Explosion
        for i in range(viral_count):
            minutes_offset = 120 + log_normal_random(2.5, 0.7) * 30
            minutes_offset = max(120, min(360, minutes_offset))
            tweet_time = base_time + timedelta(minutes=minutes_offset)
            
            if random.random() < 0.70:
                template = random.choice(CROWD_TEMPLATES_WITH_KEYWORDS)
                text = template.format(location=location)
                if random.random() < 0.3:
                    text += f" #Ù…Ø¶Ø§Ø±Ø¨Ø©_{location}"
            else:
                text = random.choice(CROWD_TEMPLATES_NOISE)
                if random.random() < 0.5:
                    text += f" #ØªØ±Ù†Ø¯_Ø§Ù„Ø±ÙŠØ§Ø¶"
            
            tweet = create_tweet(
                text=text,
                created_at=tweet_time,
                author_name=generate_display_name(),
                author_username=generate_username()
            )
            tweets.append(tweet)
            
        # Phase 3: Tail
        for i in range(tail_count):
            minutes_offset = 360 + random.expovariate(0.01)
            minutes_offset = min(minutes_offset, 1440)
            tweet_time = base_time + timedelta(minutes=minutes_offset)
            
            if random.random() < 0.5:
                template = random.choice(CROWD_TEMPLATES_WITH_KEYWORDS)
                text = template.format(location=location)
            else:
                text = random.choice(CROWD_TEMPLATES_NOISE)
                
            tweet = create_tweet(
                text=text,
                created_at=tweet_time,
                author_name=generate_display_name(),
                author_username=generate_username()
            )
            tweets.append(tweet)

    # ========== PHASE 4: Daily Content (Throughout the day) ==========
    for i in range(daily_total):
        minutes_offset = random.uniform(0, 1440)
        tweet_time = base_time + timedelta(minutes=minutes_offset)
        
        text = random.choice(DAILY_CONTENT_TEMPLATES)
        has_image = random.random() < 0.15
        
        tweet = create_tweet(
            text=text,
            created_at=tweet_time,
            author_name=generate_display_name(),
            author_username=generate_username()
        )
        
        if has_image:
            tweet["media"] = [{
                "type": "photo",
                "media_key": f"img_{uuid.uuid4().hex[:8]}",
                "url": "https://picsum.photos/600/400"
            }]
        
        tweets.append(tweet)
    
    # Sort by timestamp
    tweets.sort(key=lambda t: t["created_at"])
    
    return tweets


def get_volume_by_hour(tweets: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """Calculate tweet volume per hour for charting."""
    volume = {}
    
    for tweet in tweets:
        dt = datetime.fromisoformat(tweet["created_at"].replace("Z", ""))
        hour = dt.hour
        volume[hour] = volume.get(hour, 0) + 1
    
    return [{"hour": h, "count": volume.get(h, 0)} for h in range(24)]


if __name__ == "__main__":
    # Test data generation
    tweets = generate_synthetic_dataset()
    print(f"Generated {len(tweets)} tweets")
    
    # Find source
    source = next(t for t in tweets if t.get("is_source"))
    print(f"Source tweet at: {source['created_at']}")
    print(f"Source text: {source['text']}")
    
    # Volume distribution
    volume = get_volume_by_hour(tweets)
    print("\nVolume by hour:")
    for v in volume:
        bar = "â–ˆ" * (v["count"] // 20)
        print(f"  {v['hour']:02d}:00 | {bar} ({v['count']})")
